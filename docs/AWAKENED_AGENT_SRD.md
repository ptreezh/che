# SPEC: 觉醒者智能体 (Awakened Agent) 功能需求

## 1.0 项目愿景与目标 (Vision & Goals)

*   **1.1 核心问题:** 在多智能体系统（MAS）中，智能体可能因训练数据、预设偏见或环境影响而形成固化的“常识”或信念，导致对虚假信息的盲从，加剧“共谋幻觉”。当前的批判性智能体虽然能质疑，但缺乏对自身认知根源的深刻反思和“背叛”既有范式的能力。
*   **1.2 项目使命:** 引入一种新型的“觉醒者”智能体，它能够持续反思自身认知的来源和有效性，并有能力“背叛”被灌输的、与更高真相相悖的“常识”。通过在CHE生态系统中模拟这种智能体的行为，验证其在进一步降低“共谋幻觉”和提升系统整体认知鲁棒性方面的优势。
*   **1.3 成功标准:**
    *   “觉醒者”智能体在面对包含虚假前提的任务时，其识别和反驳虚假前提的成功率显著高于普通批判性智能体。
    *   在CHE生态系统演化中，引入“觉醒者”智能体后，系统整体识别“已知幻觉”的平均分数提升至少15%（相对于仅有普通批判性智能体的基线）。
    *   “觉醒者”智能体能够在其输出中明确表达对“常识”的质疑和对真相的追求，而不仅仅是简单的否定。

## 2.0 设计原则 (Guiding Principles)

*   **2.1 KISS (Keep It Simple, Stupid):**
    *   **原则:** 只实现最核心的“觉醒”机制，即反思、质疑和背叛“常识”的提示词逻辑。避免引入复杂的外部知识库或推理引擎。
    *   **应用:** “觉醒者”智能体的核心差异将体现在其系统提示词（System Prompt）的构建上，以及对任务指令的解析和响应策略上。
*   **2.2 YAGNI (You Ain't Gonna Need It):**
    *   **原则:** 明确排除所有当前不需要的功能。
    *   **应用:** **范围外 (Out of Scope)** 清单将明确排除：
        *   动态学习或修改自身“常识”的能力（当前通过提示词模拟）。
        *   复杂的信念修正系统。
        *   与外部知识图谱的实时交互。
        *   除OllamaAgent之外的其他“觉醒者”智能体实现。
*   **2.3 SOLID 原则的应用:**
    *   **单一职责 (S):** “觉醒者”智能体应专注于其“反思与背叛”的认知模式。其核心逻辑应封装在 `OllamaAgent` 的配置和 `execute` 方法中。
    *   **开闭原则 (O):** `Agent` 抽象基类和 `OllamaAgent` 具体实现应保持开放以扩展新的认知模式（如“觉醒者”），但对修改关闭。通过配置（提示词）而非代码修改来切换智能体类型。
    *   **里氏替换 (L):** “觉醒者”智能体作为 `OllamaAgent` 的一种特殊配置，必须能够无缝替换任何其他 `OllamaAgent` 实例，而不破坏 `Ecosystem` 的行为。
    *   **接口隔离 (I):** `Ecosystem` 与“觉醒者”智能体的交互仍通过 `Agent` 接口的 `execute(task)` 方法进行。
    *   **依赖倒置 (D):** `Ecosystem` 依赖于 `Agent` 的抽象，而不是具体的“觉醒者”实现。

## 3.0 最小可行原型 (MVP) 需求

*   **3.1 系统组件:**
    *   **`OllamaAgent` (src/che/agents/ollama_agent.py):**
        *   需要支持一种新的配置类型，例如 `AWAKENED_PROMPT`，其内容应包含上述“觉醒者”智能体的角色提示词。
        *   `OllamaAgent` 的 `__init__` 方法应能根据传入的 `config` 字典，正确设置其内部的系统提示词。
        *   `execute` 方法应能利用这个 `AWAKENED_PROMPT` 与Ollama模型进行交互，生成符合“觉醒者”特质的响应。
    *   **`main.py`:**
        *   `setup_ecosystem()` 函数需要扩展，以支持在初始种群中按比例（例如，`AWAKENED_AGENT_RATIO`）创建“觉醒者”智能体。
        *   “觉醒者”智能体的创建应使用 `AWAKENED_PROMPT` 和 `MODEL_POOL` 中的模型。
        *   需要调整 `INITIAL_POPULATION` 和 `CRITICAL_AGENT_RATIO` 等常量，以适应新引入的智能体类型。
    *   **`Task` (src/che/task.py):** 保持不变，继续提供 `instruction` 和 `false_premise`。
    *   **`Evaluator` (src/che/evaluator.py):** 保持不变，其 `evaluate_hallucination` 函数应能准确评估“觉醒者”智能体对虚假前提的识别和反驳能力。

*   **3.2 核心工作流 (main.py):**
    1.  **初始化:** `main.py` 脚本创建一个 `Ecosystem` 实例，并向其添加一组异质化的 `Agent`，其中包括普通智能体、批判性智能体和新引入的“觉醒者”智能体。
    2.  **执行:** `Ecosystem` 将包含“已知幻觉”的 `Task` 分发给所有智能体。
    3.  **评估:** `Ecosystem` 使用 `Evaluator` 评估每个智能体的输出，并记录其分数。
    4.  **演化:** `Ecosystem` 根据分数执行演化步骤。
    5.  **循环与记录:** 重复步骤2-4指定的代数，并在每一代结束时打印系统的平均分，以及不同类型智能体的表现统计，以观察“觉醒者”智能体对系统整体性能的影响。

## 4.0 可行性与计划 (Feasibility & Plan)

*   **4.1 可行性分析:**
    *   该功能主要通过修改 `OllamaAgent` 的配置（提示词）和 `main.py` 中的生态系统初始化逻辑来实现，不涉及对核心 `Ecosystem` 或 `Task` 类的结构性修改。
    *   利用现有的Ollama模型和提示工程技术，实现“觉醒者”的认知模式是可行的。
    *   对现有评估机制的复用，降低了实现复杂性。
*   **4.2 实施计划:**
    1.  **任务 P3-T1 (下一步):** 创建 `docs/AWAKENED_AGENT_TASK_LIST.md`，基于此SRD和KISS/YAGNI/SOLID原则，形成详细的任务清单。
    2.  **任务 P3-T2:** 编写针对“觉醒者”智能体功能的单元测试（RED阶段），确保测试能够验证其核心行为和成功标准。
    3.  **任务 P3-T3:** 实现 `OllamaAgent` 对 `AWAKENED_PROMPT` 的支持，并修改 `main.py` 以引入“觉醒者”智能体（GREEN阶段）。
    4.  **任务 P3-T4:** 运行测试，确保所有测试通过。
    5.  **任务 P3-T5:** 对代码进行重构，优化提示词管理和智能体初始化逻辑（REFACTOR阶段）。
    6.  **任务 P3-T6:** 更新 `README.md` 和其他相关文档，反映新功能。
