#!/usr/bin/env python3
"""
å®éªŒæ¼”ç¤ºè„šæœ¬ - æ¼”ç¤ºå¦‚ä½•è¿è¡Œè®¤çŸ¥å¼‚è´¨æ€§å®éªŒ

Authors: Zhang Shuren, AI Personality LAB
Date: 2025-09-20
"""

import sys
import os
import logging
import json
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.che.experimental.design import (
    ExperimentalDesign, ExperimentalCondition,
    DiversityLevel, EvolutionPressure, RoleConfiguration
)
from src.che.core.task import TaskFactory
from src.che.core.ecosystem import Ecosystem, create_stratified_population

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def run_simple_demo():
    """è¿è¡Œç®€å•æ¼”ç¤ºå®éªŒ"""

    print("ğŸ§¬ è®¤çŸ¥å¼‚è´¨æ€§å®éªŒç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)

    # 1. åˆ›å»ºå®éªŒæ¡ä»¶
    condition = ExperimentalCondition(
        diversity_level=DiversityLevel.LOW,
        evolution_pressure=EvolutionPressure.PRESENT,
        role_configuration=RoleConfiguration.BALANCED,
        condition_id="demo",
        replication_id=1
    )

    print(f"å®éªŒæ¡ä»¶: {condition.get_description()}")
    print(f"å¤šæ ·æ€§æ°´å¹³: {condition.diversity_level.value}")
    print(f"è¿›åŒ–å‹åŠ›: {condition.evolution_pressure.value}")
    print(f"è§’è‰²é…ç½®: {condition.role_configuration.value}")

    # 2. åˆ›å»ºæ™ºèƒ½ä½“ç§ç¾¤
    model_pool = condition.get_model_pool()
    population_size = condition.get_population_size()
    agents = create_stratified_population(model_pool, population_size)

    # 3. è°ƒæ•´è§’è‰²åˆ†å¸ƒ
    role_distribution = condition.get_role_distribution()
    _adjust_role_distribution(agents, role_distribution)

    print(f"\nåˆ›å»ºäº† {len(agents)} ä¸ªæ™ºèƒ½ä½“")

    # æ˜¾ç¤ºè§’è‰²åˆ†å¸ƒ
    role_counts = {"critical": 0, "standard": 0, "awakened": 0}
    for agent in agents:
        role_counts[agent.role] += 1

    print("è§’è‰²åˆ†å¸ƒ:")
    for role, count in role_counts.items():
        print(f"  {role}: {count} ({count/len(agents)*100:.1f}%)")

    # 4. åˆ›å»ºä»»åŠ¡
    tasks = TaskFactory.create_mixed_tasks(count_per_domain=5)
    print(f"\nåˆ›å»ºäº† {len(tasks)} ä¸ªä»»åŠ¡")

    # æ˜¾ç¤ºä»»åŠ¡åˆ†å¸ƒ
    domain_counts = {}
    for task in tasks:
        domain_counts[task.domain] = domain_counts.get(task.domain, 0) + 1

    print("ä»»åŠ¡é¢†åŸŸåˆ†å¸ƒ:")
    for domain, count in domain_counts.items():
        print(f"  {domain}: {count} ä¸ªä»»åŠ¡")

    # 5. åˆ›å»ºç”Ÿæ€ç³»ç»Ÿå¹¶è¿è¡Œæ¼”åŒ–
    ecosystem = Ecosystem(agents, tasks)
    generations = 8  # æ¼”ç¤ºç”¨è¾ƒå°‘ä»£æ•°

    print(f"\nå¼€å§‹ {generations} ä»£æ¼”åŒ–æ¼”ç¤º...")
    print("-" * 50)

    performance_history = []
    diversity_history = []

    for gen in range(generations):
        # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
        _simulate_task_execution(ecosystem)

        # è®¡ç®—æŒ‡æ ‡
        avg_performance = _calculate_average_performance(ecosystem.agents)
        diversity_index = ecosystem.calculate_diversity_index()

        performance_history.append(avg_performance)
        diversity_history.append(diversity_index)

        print(f"ç¬¬ {gen + 1:2d} ä»£ | æ€§èƒ½: {avg_performance:.3f} | å¤šæ ·æ€§: {diversity_index:.3f}")

        # æ‰§è¡Œæ¼”åŒ–ï¼ˆé™¤äº†æœ€åä¸€ä»£ï¼‰
        if gen < generations - 1:
            ecosystem.evolve_population()

    print("-" * 50)
    print(f"æœ€ç»ˆæ€§èƒ½: {performance_history[-1]:.3f}")
    print(f"æ€§èƒ½æå‡: {performance_history[-1] - performance_history[0]:.3f}")
    print(f"æœ€ç»ˆå¤šæ ·æ€§: {diversity_history[-1]:.3f}")

    # 6. ä¿å­˜ç»“æœ
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)

    result = {
        "experiment_type": "demo",
        "condition": {
            "diversity_level": condition.diversity_level.value,
            "evolution_pressure": condition.evolution_pressure.value,
            "role_configuration": condition.role_configuration.value
        },
        "generations": generations,
        "population_size": len(agents),
        "performance_trajectory": performance_history,
        "diversity_trajectory": diversity_history,
        "final_performance": performance_history[-1],
        "role_distribution": role_counts,
        "task_distribution": domain_counts
    }

    result_path = results_dir / "demo_experiment_result.json"
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(f"\næ¼”ç¤ºç»“æœå·²ä¿å­˜åˆ°: {result_path}")
    print("\nğŸ‰ æ¼”ç¤ºå®éªŒå®Œæˆ!")

    return result


def _adjust_role_distribution(agents, target_distribution):
    """è°ƒæ•´è§’è‰²åˆ†å¸ƒ"""
    from src.che.core.agent import AgentFactory

    current_counts = {"critical": 0, "standard": 0, "awakened": 0}
    for agent in agents:
        current_counts[agent.role] += 1

    target_counts = {
        role: int(count * len(agents))
        for role, count in target_distribution.items()
    }

    target_counts["awakened"] += len(agents) - sum(target_counts.values())

    for role, target_count in target_counts.items():
        while current_counts[role] < target_count:
            for agent in agents:
                if current_counts[agent.role] > target_counts.get(agent.role, 0):
                    old_role = agent.role
                    agent.role = role
                    prompts = AgentFactory.load_prompts()
                    agent.system_prompt = prompts.get(role, prompts["standard"])
                    current_counts[old_role] -= 1
                    current_counts[role] += 1
                    break


def _simulate_task_execution(ecosystem):
    """æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ"""
    import random

    for agent in ecosystem.agents:
        base_score = 0.5 + (hash(agent.id) % 100) / 200
        role_bonus = {
            "critical": 0.1,
            "standard": 0.05,
            "awakened": 0.15
        }.get(agent.role, 0.0)

        random.seed(hash(agent.id + str(ecosystem.generation)))
        noise = random.uniform(-0.05, 0.05)

        agent.fitness_score = max(0.0, min(1.0, base_score + role_bonus + noise))


def _calculate_average_performance(agents):
    """è®¡ç®—å¹³å‡æ€§èƒ½"""
    if not agents:
        return 0.0
    return sum(agent.fitness_score for agent in agents) / len(agents)


def run_comparison_demo():
    """è¿è¡Œå¯¹æ¯”æ¼”ç¤ºå®éªŒ"""

    print("\n" + "=" * 60)
    print("ğŸ”¬ å¯¹æ¯”æ¼”ç¤ºå®éªŒ - é«˜å¤šæ ·æ€§ vs ä½å¤šæ ·æ€§")
    print("=" * 60)

    # ä¸¤ä¸ªå®éªŒæ¡ä»¶å¯¹æ¯”
    conditions = [
        ExperimentalCondition(
            diversity_level=DiversityLevel.LOW,
            evolution_pressure=EvolutionPressure.PRESENT,
            role_configuration=RoleConfiguration.BALANCED,
            condition_id="low_diversity",
            replication_id=1
        ),
        ExperimentalCondition(
            diversity_level=DiversityLevel.HIGH,
            evolution_pressure=EvolutionPressure.PRESENT,
            role_configuration=RoleConfiguration.BALANCED,
            condition_id="high_diversity",
            replication_id=1
        )
    ]

    results = {}

    for condition in conditions:
        print(f"\n{condition.diversity_level.value.upper()} å¤šæ ·æ€§å®éªŒ:")
        print("-" * 30)

        # åˆ›å»ºå®éªŒè®¾ç½®
        model_pool = condition.get_model_pool()
        population_size = condition.get_population_size()
        agents = create_stratified_population(model_pool, population_size)
        _adjust_role_distribution(agents, condition.get_role_distribution())

        tasks = TaskFactory.create_mixed_tasks(count_per_domain=3)
        ecosystem = Ecosystem(agents, tasks)

        generations = 6
        performance_history = []

        for gen in range(generations):
            _simulate_task_execution(ecosystem)
            avg_performance = _calculate_average_performance(ecosystem.agents)
            performance_history.append(avg_performance)
            print(f"ç¬¬ {gen + 1} ä»£: {avg_performance:.3f}")

            if gen < generations - 1:
                ecosystem.evolve_population()

        results[condition.diversity_level.value] = {
            "performance": performance_history,
            "final_performance": performance_history[-1],
            "population_size": len(agents)
        }

        print(f"æœ€ç»ˆæ€§èƒ½: {performance_history[-1]:.3f}")

    # æ¯”è¾ƒç»“æœ
    print("\n" + "=" * 40)
    print("ğŸ“Š å¯¹æ¯”ç»“æœ:")
    print("=" * 40)

    low_result = results["low"]
    high_result = results["high"]

    print(f"ä½å¤šæ ·æ€§: {low_result['final_performance']:.3f} (ç§ç¾¤: {low_result['population_size']})")
    print(f"é«˜å¤šæ ·æ€§: {high_result['final_performance']:.3f} (ç§ç¾¤: {high_result['population_size']})")
    print(f"æ€§èƒ½å·®å¼‚: {high_result['final_performance'] - low_result['final_performance']:.3f}")

    if high_result['final_performance'] > low_result['final_performance']:
        print("âœ… é«˜å¤šæ ·æ€§è¡¨ç°æ›´å¥½")
    else:
        print("â“ éœ€è¦æ›´å¤šæ•°æ®éªŒè¯")

    return results


if __name__ == "__main__":
    print("é€‰æ‹©æ¼”ç¤ºç±»å‹:")
    print("1. ç®€å•æ¼”ç¤º (å•ä¸ªå®éªŒ)")
    print("2. å¯¹æ¯”æ¼”ç¤º (å¤šæ ·æ€§å¯¹æ¯”)")

    # ç”±äºæ˜¯æ¼”ç¤ºï¼Œé»˜è®¤è¿è¡Œç®€å•æ¼”ç¤º
    print("\né»˜è®¤è¿è¡Œç®€å•æ¼”ç¤º...")
    demo_result = run_simple_demo()

    # è¯¢é—®æ˜¯å¦è¿è¡Œå¯¹æ¯”æ¼”ç¤º
    print(f"\næ˜¯å¦ç»§ç»­è¿è¡Œå¯¹æ¯”æ¼”ç¤º? (æ€§èƒ½å¯¹æ¯”å®éªŒ)")
    print("è¿™ä¸ªæ¼”ç¤ºä¼šå¯¹æ¯”é«˜å¤šæ ·æ€§å’Œä½å¤šæ ·æ€§çš„æ•ˆæœ")

    # ç”±äºåœ¨è„šæœ¬ç¯å¢ƒä¸­ï¼Œè‡ªåŠ¨è¿è¡Œå¯¹æ¯”æ¼”ç¤º
    print("\nè‡ªåŠ¨è¿è¡Œå¯¹æ¯”æ¼”ç¤º...")
    comparison_result = run_comparison_demo()

    print(f"\nğŸ¯ æ¼”ç¤ºæ€»ç»“:")
    print(f"å®Œæˆäº† {len([demo_result, comparison_result])} ä¸ªæ¼”ç¤ºå®éªŒ")
    print(f"ç»“æœä¿å­˜åœ¨ results/ ç›®å½•ä¸­")
    print(f"å¯ä»¥æŸ¥çœ‹ JSON æ–‡ä»¶äº†è§£è¯¦ç»†æ•°æ®")