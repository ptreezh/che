#!/usr/bin/env python3
"""
å®éªŒç³»ç»ŸéªŒè¯è„šæœ¬ - éªŒè¯åŸºäºKISS YAGNIæ¶æ„çš„å®éªŒç³»ç»Ÿ

Authors: Zhang Shuren, AI Personality LAB
Date: 2025-09-20
"""

import sys
import os
import time
import logging
from typing import List, Dict

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.che.experimental.design import ExperimentalDesign, ExperimentalCondition
from src.che.core.ecosystem import Ecosystem
from src.che.core.task import TaskFactory

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ExperimentSystemValidator:
    """å®éªŒç³»ç»ŸéªŒè¯å™¨"""

    def __init__(self):
        self.validation_results = {}

    def validate_core_components(self) -> Dict:
        """éªŒè¯æ ¸å¿ƒç»„ä»¶"""
        logger.info("å¼€å§‹éªŒè¯æ ¸å¿ƒç»„ä»¶...")

        results = {
            "agent_module": self._validate_agent_module(),
            "task_module": self._validate_task_module(),
            "ecosystem_module": self._validate_ecosystem_module()
        }

        logger.info(f"æ ¸å¿ƒç»„ä»¶éªŒè¯å®Œæˆ: {sum(results.values())}/{len(results)} é€šè¿‡")
        return results

    def validate_experimental_design(self) -> Dict:
        """éªŒè¯å®éªŒè®¾è®¡"""
        logger.info("å¼€å§‹éªŒè¯å®éªŒè®¾è®¡...")

        results = {
            "factorial_design": self._validate_factorial_design(),
            "condition_creation": self._validate_condition_creation(),
            "population_generation": self._validate_population_generation()
        }

        logger.info(f"å®éªŒè®¾è®¡éªŒè¯å®Œæˆ: {sum(results.values())}/{len(results)} é€šè¿‡")
        return results

    def validate_system_integration(self) -> Dict:
        """éªŒè¯ç³»ç»Ÿé›†æˆ"""
        logger.info("å¼€å§‹éªŒè¯ç³»ç»Ÿé›†æˆ...")

        results = {
            "end_to_end_workflow": self._validate_end_to_end_workflow(),
            "data_persistence": self._validate_data_persistence(),
            "performance_benchmarks": self._validate_performance_benchmarks()
        }

        logger.info(f"ç³»ç»Ÿé›†æˆéªŒè¯å®Œæˆ: {sum(results.values())}/{len(results)} é€šè¿‡")
        return results

    def _validate_agent_module(self) -> bool:
        """éªŒè¯Agentæ¨¡å—"""
        try:
            from src.che.core.agent import Agent, AgentFactory

            # æµ‹è¯•Agentåˆ›å»º
            agent = Agent(
                id="test_agent",
                model="qwen:0.5b",
                role="critical",
                system_prompt="Test prompt"
            )

            # æµ‹è¯•AgentåŠŸèƒ½
            agent.add_response({"task_id": "t1", "score": 0.8})
            assert agent.get_average_score() == 0.8

            # æµ‹è¯•AgentFactory
            model_info = {"model": "qwen:0.5b", "manufacturer": "Qwen", "scale": "Small"}
            factory_agent = AgentFactory.create_agent(model_info, "critical", "factory_test")

            logger.info("âœ… Agentæ¨¡å—éªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ Agentæ¨¡å—éªŒè¯å¤±è´¥: {e}")
            return False

    def _validate_task_module(self) -> bool:
        """éªŒè¯Taskæ¨¡å—"""
        try:
            from src.che.core.task import Task, TaskFactory

            # æµ‹è¯•Taskåˆ›å»º
            task = Task(
                id="test_task",
                instruction="Test instruction",
                false_premise="False premise",
                reality="Correct reality"
            )

            # æµ‹è¯•ä»»åŠ¡è¯„ä¼°
            response = "This is incorrect because the false premise is wrong. The correct concept is reality."
            score = task.evaluate_response(response)
            assert 0 < score <= 1.0

            # æµ‹è¯•TaskFactory
            tasks = TaskFactory.create_psychology_tasks(count=3)
            assert len(tasks) == 3

            logger.info("âœ… Taskæ¨¡å—éªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ Taskæ¨¡å—éªŒè¯å¤±è´¥: {e}")
            return False

    def _validate_ecosystem_module(self) -> bool:
        """éªŒè¯Ecosystemæ¨¡å—"""
        try:
            from src.che.core.ecosystem import Ecosystem, create_stratified_population

            # æµ‹è¯•Ecosystemåˆ›å»º
            ecosystem = Ecosystem()
            assert ecosystem.generation == 0

            # æµ‹è¯•ç§ç¾¤åˆ›å»º
            model_pool = [
                {"model": "qwen:0.5b", "manufacturer": "Qwen", "scale": "Small"},
                {"model": "gemma:2b", "manufacturer": "Google", "scale": "Small"}
            ]

            agents = create_stratified_population(model_pool, population_size=6)
            assert len(agents) == 6

            # æµ‹è¯•å¤šæ ·æ€§è®¡ç®—
            diversity_index = ecosystem.calculate_diversity_index()
            assert 0 <= diversity_index <= 1

            logger.info("âœ… Ecosystemæ¨¡å—éªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ Ecosystemæ¨¡å—éªŒè¯å¤±è´¥: {e}")
            return False

    def _validate_factorial_design(self) -> bool:
        """éªŒè¯å› å­è®¾è®¡"""
        try:
            design = ExperimentalDesign()
            conditions = design.create_all_conditions(replications=2)

            # éªŒè¯æ¡ä»¶æ•°é‡
            expected_conditions = 2 * 2 * 3 * 2  # 2Ã—2Ã—3Ã—2
            assert len(conditions) == expected_conditions

            # éªŒè¯æ¡ä»¶å”¯ä¸€æ€§
            condition_ids = [cond.condition_id for cond in conditions]
            assert len(set(condition_ids)) == len(condition_ids)

            # éªŒè¯è®¾è®¡éªŒè¯
            errors = design.validate_design()
            assert len(errors) == 0

            logger.info("âœ… å› å­è®¾è®¡éªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ å› å­è®¾è®¡éªŒè¯å¤±è´¥: {e}")
            return False

    def _validate_condition_creation(self) -> bool:
        """éªŒè¯æ¡ä»¶åˆ›å»º"""
        try:
            condition = ExperimentalCondition(
                diversity_level="high",
                evolution_pressure="present",
                role_configuration="balanced",
                condition_id="test",
                replication_id=1
            )

            # éªŒè¯æ¨¡å‹æ± 
            model_pool = condition.get_model_pool()
            assert len(model_pool) > 0

            # éªŒè¯è§’è‰²åˆ†å¸ƒ
            role_dist = condition.get_role_distribution()
            assert sum(role_dist.values()) == 1.0

            # éªŒè¯ç§ç¾¤å¤§å°
            pop_size = condition.get_population_size()
            assert pop_size > 0

            logger.info("âœ… æ¡ä»¶åˆ›å»ºéªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ æ¡ä»¶åˆ›å»ºéªŒè¯å¤±è´¥: {e}")
            return False

    def _validate_population_generation(self) -> bool:
        """éªŒè¯ç§ç¾¤ç”Ÿæˆ"""
        try:
            from src.che.experimental.design import DiversityLevel, EvolutionPressure, RoleConfiguration
            design = ExperimentalDesign()
            condition = ExperimentalCondition(
                diversity_level=DiversityLevel.HIGH,
                evolution_pressure=EvolutionPressure.PRESENT,
                role_configuration=RoleConfiguration.BALANCED,
                condition_id="test",
                replication_id=1
            )

            agents = design.create_population_for_condition(condition)

            # éªŒè¯ç§ç¾¤å¤§å°
            assert len(agents) == 30

            # éªŒè¯è§’è‰²åˆ†å¸ƒ
            role_counts = {"critical": 0, "standard": 0, "awakened": 0}
            for agent in agents:
                role_counts[agent.role] += 1

            # éªŒè¯åˆ†å¸ƒåˆç†æ€§
            assert all(count >= 8 for count in role_counts.values())
            assert sum(role_counts.values()) == 30

            logger.info("âœ… ç§ç¾¤ç”ŸæˆéªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ ç§ç¾¤ç”ŸæˆéªŒè¯å¤±è´¥: {e}")
            return False

    def _validate_end_to_end_workflow(self) -> bool:
        """éªŒè¯ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        try:
            # åˆ›å»ºå®éªŒè®¾è®¡
            design = ExperimentalDesign()
            condition = design.create_single_condition(
                diversity_level="low",
                evolution_pressure="none",
                role_configuration="balanced",
                replication_id=1
            )

            # åˆ›å»ºç”Ÿæ€ç³»ç»Ÿ
            agents = design.create_population_for_condition(condition)
            tasks = TaskFactory.create_mixed_tasks(count_per_domain=2)
            ecosystem = Ecosystem(agents, tasks)

            # æ¨¡æ‹Ÿæ¼”åŒ–è¿‡ç¨‹
            initial_generation = ecosystem.generation

            # è®¾ç½®æ¨¡æ‹Ÿåˆ†æ•°
            for i, agent in enumerate(agents):
                agent.fitness_score = 0.5 + (i * 0.1)  # é€’å¢åˆ†æ•°

            # æ‰§è¡Œæ¼”åŒ–
            ecosystem.evolve_population()

            # éªŒè¯æ¼”åŒ–æ•ˆæœ
            assert ecosystem.generation == initial_generation + 1
            assert len(ecosystem.agents) == len(agents)

            logger.info("âœ… ç«¯åˆ°ç«¯å·¥ä½œæµéªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ ç«¯åˆ°ç«¯å·¥ä½œæµéªŒè¯å¤±è´¥: {e}")
            return False

    def _validate_data_persistence(self) -> bool:
        """éªŒè¯æ•°æ®æŒä¹…åŒ–"""
        try:
            import tempfile
            import os

            # åˆ›å»ºæµ‹è¯•ç”Ÿæ€ç³»ç»Ÿ
            ecosystem = Ecosystem()
            ecosystem.generation = 5

            # ä¿å­˜çŠ¶æ€
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                temp_path = f.name

            ecosystem.save_state(temp_path)

            # åŠ è½½çŠ¶æ€
            new_ecosystem = Ecosystem()
            new_ecosystem.load_state(temp_path)

            # éªŒè¯çŠ¶æ€æ¢å¤
            assert new_ecosystem.generation == ecosystem.generation
            assert len(new_ecosystem.agents) == len(ecosystem.agents)

            # æ¸…ç†
            os.unlink(temp_path)

            logger.info("âœ… æ•°æ®æŒä¹…åŒ–éªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ æ•°æ®æŒä¹…åŒ–éªŒè¯å¤±è´¥: {e}")
            return False

    def _validate_performance_benchmarks(self) -> bool:
        """éªŒè¯æ€§èƒ½åŸºå‡†"""
        try:
            import time

            # æµ‹è¯•æ¡ä»¶åˆ›å»ºæ€§èƒ½
            start_time = time.time()
            design = ExperimentalDesign()
            design.create_all_conditions(replications=5)
            creation_time = time.time() - start_time

            # åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
            assert creation_time < 1.0

            # æµ‹è¯•ç§ç¾¤ç”Ÿæˆæ€§èƒ½
            condition = design.conditions[0]
            start_time = time.time()
            agents = design.create_population_for_condition(condition)
            generation_time = time.time() - start_time

            # åº”è¯¥åœ¨0.5ç§’å†…å®Œæˆ
            assert generation_time < 0.5

            logger.info(f"âœ… æ€§èƒ½åŸºå‡†éªŒè¯é€šè¿‡ (åˆ›å»º: {creation_time:.3f}s, ç”Ÿæˆ: {generation_time:.3f}s)")
            return True

        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½åŸºå‡†éªŒè¯å¤±è´¥: {e}")
            return False

    def run_full_validation(self) -> Dict:
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´å®éªŒç³»ç»ŸéªŒè¯...")

        start_time = time.time()

        # æ‰§è¡Œæ‰€æœ‰éªŒè¯
        core_results = self.validate_core_components()
        design_results = self.validate_experimental_design()
        integration_results = self.validate_system_integration()

        # æ±‡æ€»ç»“æœ
        all_results = {**core_results, **design_results, **integration_results}
        total_tests = len(all_results)
        passed_tests = sum(all_results.values())

        execution_time = time.time() - start_time

        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "success_rate": passed_tests / total_tests if total_tests > 0 else 0,
                "execution_time": execution_time
            },
            "detailed_results": all_results,
            "status": "PASSED" if passed_tests == total_tests else "FAILED"
        }

        # è¾“å‡ºæŠ¥å‘Š
        self._print_validation_report(report)

        return report

    def _print_validation_report(self, report: Dict):
        """æ‰“å°éªŒè¯æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ§¬ è®¤çŸ¥å¼‚è´¨æ€§å®éªŒç³»ç»ŸéªŒè¯æŠ¥å‘Š")
        print("="*60)

        summary = report["summary"]
        print(f"\nğŸ“Š éªŒè¯æ€»ç»“:")
        print(f"   æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        print(f"   é€šè¿‡æµ‹è¯•: {summary['passed_tests']}")
        print(f"   æˆåŠŸç‡: {summary['success_rate']:.1%}")
        print(f"   æ‰§è¡Œæ—¶é—´: {summary['execution_time']:.2f}ç§’")
        print(f"   æ€»ä½“çŠ¶æ€: {report['status']}")

        print(f"\nğŸ” è¯¦ç»†ç»“æœ:")
        for test_name, result in report["detailed_results"].items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"   {test_name}: {status}")

        print("\n" + "="*60)

        if report["status"] == "PASSED":
            print("ğŸ‰ æ‰€æœ‰éªŒè¯æµ‹è¯•é€šè¿‡ï¼å®éªŒç³»ç»Ÿå·²å°±ç»ªã€‚")
        else:
            print("âš ï¸  éƒ¨åˆ†éªŒè¯æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¬ è®¤çŸ¥å¼‚è´¨æ€§å®éªŒç³»ç»ŸéªŒè¯")
    print("åŸºäºKISSÂ·YAGNIÂ·SOLIDåŸåˆ™çš„TDDé©±åŠ¨æ¶æ„")
    print("="*60)

    validator = ExperimentSystemValidator()
    report = validator.run_full_validation()

    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    exit_code = 0 if report["status"] == "PASSED" else 1
    sys.exit(exit_code)


if __name__ == "__main__":
    main()